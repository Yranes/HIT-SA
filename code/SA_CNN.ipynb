{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGwVB2m4dEOI",
        "outputId": "751ef52a-da1e-4bc9-e96a-141c45e9a932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (0.42.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install jieba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GskWd5sfs37n",
        "outputId": "ac4f33aa-2aaa-4c00-fdd1-0d3246992951"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0HYU55LVl7J"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gensim\n",
        "import jieba\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSjWdn0cfDED"
      },
      "outputs": [],
      "source": [
        "PAD = '<PAD>'\n",
        "UNK = '<UNK>'\n",
        "\n",
        "label_dic = {'positive': 1, 'negative': 2, 'neutral': 0}\n",
        "\n",
        "def read_json(file_path):\n",
        "    with open(file_path, 'r', encoding = 'utf-8') as f:\n",
        "      anslist = json.load(f)\n",
        "    return anslist\n",
        "\n",
        "def build_dataset(file_path, mode, wv, padding_size = 32):\n",
        "    assert mode in ['train', 'test']\n",
        "    res = read_json(file_path)\n",
        "    text, labels = [], []\n",
        "    for dic in tqdm(res):\n",
        "        corpus = dic['content']\n",
        "        if mode == 'train':\n",
        "            label = label_dic[dic['label']]\n",
        "        words = list(jieba.cut(corpus))\n",
        "        if len(words) < padding_size:\n",
        "            words += [PAD] * (padding_size - len(words))\n",
        "        else:\n",
        "            words = words[: padding_size]\n",
        "        unk_idx = wv.word2idx[UNK]\n",
        "        idxs = [wv.word2idx.get(word, unk_idx) for word in words]\n",
        "        if mode == 'train':\n",
        "            text.append(idxs)\n",
        "            labels.append(label)\n",
        "        else:\n",
        "            text.append(idxs)\n",
        "    if mode == 'train':\n",
        "        return text, labels\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "class Mydataset(Dataset):\n",
        "    def __init__(self, file_path, mode, wv):\n",
        "        if mode == 'train':\n",
        "            self.x, self.y = build_dataset(file_path, mode, wv)\n",
        "            assert len(self.x) == len(self.y)\n",
        "            self.y = torch.tensor(self.y)\n",
        "        else:\n",
        "            self.x = build_dataset(file_path, mode, wv)\n",
        "        self.mode = mode\n",
        "        self.x = torch.tensor(self.x)\n",
        "        self.len = len(self.x)\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    def __getitem__(self, index):\n",
        "        if self.mode == 'train':\n",
        "            return self.x[index], self.y[index]\n",
        "        else:\n",
        "            return self.x[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QoMnEQkY51Rm"
      },
      "outputs": [],
      "source": [
        "class word2vec():\n",
        "  def __init__(self, pretrained_w2v_path = '/content/drive/MyDrive/情感分类实验数据2023/sgns.weibo.bigram-char'):\n",
        "    w2vmodel = gensim.models.KeyedVectors.load_word2vec_format(pretrained_w2v_path, binary = False, encoding = 'utf-8')\n",
        "    self.vocab_size = len(w2vmodel.index_to_key)\n",
        "    self.word2idx = w2vmodel.key_to_index\n",
        "    self.word2idx.update({'<UNK>': self.vocab_size, '<PAD>': self.vocab_size + 1})\n",
        "    self.vocab_size += 2\n",
        "    self.vector_size = w2vmodel.vector_size\n",
        "    self.vocab = w2vmodel.index_to_key\n",
        "    self.vocab.append('<UNK>')\n",
        "    self.vocab.append('<PAD>')\n",
        "    self.vectors = w2vmodel.vectors\n",
        "    self.vectors = torch.tensor(np.append(np.append(\n",
        "        self.vectors, self.vectors.mean(axis=0).reshape(1,-1), axis=0),\n",
        "        self.vectors.mean(axis=0).reshape(1,-1), axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXhH_OCfYpAz"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, w2vmodel, drop_rate = 0.3, conv_channel = 4, train_path = '/content/drive/MyDrive/情感分类实验数据2023/public-data/train_data/train_data.json',\n",
        "               eval_path = '/content/drive/MyDrive/情感分类实验数据2023/public-data/eval_data/eval_data.json',\n",
        "               test_path = '/content/drive/MyDrive/情感分类实验数据2023/public-data/test_data/test.json'):\n",
        "    super(CNN, self).__init__()\n",
        "    self.embedding = nn.Embedding.from_pretrained(w2vmodel.vectors, freeze=True)\n",
        "    embedding_dim = w2vmodel.vector_size\n",
        "    self.Conv1 = nn.Conv2d(1, conv_channel, (1, embedding_dim))\n",
        "    self.Conv2 = nn.Conv2d(1, conv_channel, (2, embedding_dim))\n",
        "    self.Conv3 = nn.Conv2d(1, conv_channel, (3, embedding_dim))\n",
        "    self.Conv4 = nn.Conv2d(1, conv_channel, (4, embedding_dim))\n",
        "    self.Dropout = nn.Dropout(drop_rate)\n",
        "    self.Fc = nn.Linear(conv_channel * 4, 3)\n",
        "\n",
        "  def forward(self, input):\n",
        "    embeds = self.embedding(input)\n",
        "    embeds = embeds.unsqueeze(1)\n",
        "    conv1_out = torch.max(self.Conv1(embeds), dim = 2)[0].squeeze(-1)\n",
        "    conv2_out = torch.max(self.Conv2(embeds), dim = 2)[0].squeeze(-1)\n",
        "    conv3_out = torch.max(self.Conv3(embeds), dim = 2)[0].squeeze(-1)\n",
        "    conv4_out = torch.max(self.Conv4(embeds), dim = 2)[0].squeeze(-1)\n",
        "\n",
        "    conv_out = torch.cat((conv1_out, conv2_out, conv3_out, conv4_out), dim=1)\n",
        "    output = self.Dropout(conv_out)\n",
        "    output = self.Fc(conv_out)\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l-oHosO2wux"
      },
      "outputs": [],
      "source": [
        "w2v = word2vec()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb2Q-1wr9_0z"
      },
      "outputs": [],
      "source": [
        "model = CNN(w2v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMn4BGck27nf",
        "outputId": "1edbfcf8-1bfc-4055-9692-41438977a83f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "195199"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(w2v.vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F230Scn6Q4Qq",
        "outputId": "e0e4b2d0-ef32-4d0f-8838-8d0a6c00d2d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8606/8606 [00:01<00:00, 4912.66it/s]\n"
          ]
        }
      ],
      "source": [
        "train_data = Mydataset('/content/drive/MyDrive/情感分类实验数据2023/public-data/train_data/train_data.json', mode='train', wv=w2v)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GcsjYVi7wGF"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as Fun\n",
        "\n",
        "def train(model, train_iter):\n",
        "    # 启用dropout\n",
        "    model.train()\n",
        "    # 设置adam优化器\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    for epoch in range(150):\n",
        "      print(\"Epoch [{}/{}]\".format(epoch+1, 150))\n",
        "      for i,(trains,labels) in enumerate(train_iter):\n",
        "        outputs = model(trains)\n",
        "        model.zero_grad()\n",
        "        loss = Fun.cross_entropy(outputs, labels)\n",
        "        if i == 0:\n",
        "          print(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQmQWuFZ-se9",
        "outputId": "0584af20-5578-4a60-bb91-a03aa4aecb6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/150]\n",
            "0.01083025336265564\n",
            "Epoch [2/150]\n",
            "0.008436683565378189\n",
            "Epoch [3/150]\n",
            "0.01412936206907034\n",
            "Epoch [4/150]\n",
            "0.011085019446909428\n",
            "Epoch [5/150]\n",
            "0.007467744406312704\n",
            "Epoch [6/150]\n",
            "0.009604339487850666\n",
            "Epoch [7/150]\n",
            "0.010187134146690369\n",
            "Epoch [8/150]\n",
            "0.010816633701324463\n",
            "Epoch [9/150]\n",
            "0.01376034040004015\n",
            "Epoch [10/150]\n",
            "0.008771408349275589\n",
            "Epoch [11/150]\n",
            "0.009532655589282513\n",
            "Epoch [12/150]\n",
            "0.010728029534220695\n",
            "Epoch [13/150]\n",
            "0.01007876731455326\n",
            "Epoch [14/150]\n",
            "0.010083887726068497\n",
            "Epoch [15/150]\n",
            "0.014406884089112282\n",
            "Epoch [16/150]\n",
            "0.01081971637904644\n",
            "Epoch [17/150]\n",
            "0.010185056366026402\n",
            "Epoch [18/150]\n",
            "0.009118973277509212\n",
            "Epoch [19/150]\n",
            "0.009724986739456654\n",
            "Epoch [20/150]\n",
            "0.009506264701485634\n",
            "Epoch [21/150]\n",
            "0.012435771524906158\n",
            "Epoch [22/150]\n",
            "0.009844368323683739\n",
            "Epoch [23/150]\n",
            "0.010964572429656982\n",
            "Epoch [24/150]\n",
            "0.010279026813805103\n",
            "Epoch [25/150]\n",
            "0.00913620088249445\n",
            "Epoch [26/150]\n",
            "0.009834842756390572\n",
            "Epoch [27/150]\n",
            "0.009561119601130486\n",
            "Epoch [28/150]\n",
            "0.009828882291913033\n",
            "Epoch [29/150]\n",
            "0.009371047839522362\n",
            "Epoch [30/150]\n",
            "0.010418904945254326\n",
            "Epoch [31/150]\n",
            "0.008824971504509449\n",
            "Epoch [32/150]\n",
            "0.00872809812426567\n",
            "Epoch [33/150]\n",
            "0.008084389381110668\n",
            "Epoch [34/150]\n",
            "0.009104416705667973\n",
            "Epoch [35/150]\n",
            "0.008964735083281994\n",
            "Epoch [36/150]\n",
            "0.008014276623725891\n",
            "Epoch [37/150]\n",
            "0.008641532622277737\n",
            "Epoch [38/150]\n",
            "0.007638107519596815\n",
            "Epoch [39/150]\n",
            "0.010167804546654224\n",
            "Epoch [40/150]\n",
            "0.008413457311689854\n",
            "Epoch [41/150]\n",
            "0.008864697068929672\n",
            "Epoch [42/150]\n",
            "0.007775706239044666\n",
            "Epoch [43/150]\n",
            "0.008873180486261845\n",
            "Epoch [44/150]\n",
            "0.008110321126878262\n",
            "Epoch [45/150]\n",
            "0.006963188759982586\n",
            "Epoch [46/150]\n",
            "0.010537461377680302\n",
            "Epoch [47/150]\n",
            "0.008861707523465157\n",
            "Epoch [48/150]\n",
            "0.007556507363915443\n",
            "Epoch [49/150]\n",
            "0.007567930035293102\n",
            "Epoch [50/150]\n",
            "0.008971060626208782\n",
            "Epoch [51/150]\n",
            "0.00853576697409153\n",
            "Epoch [52/150]\n",
            "0.008328941650688648\n",
            "Epoch [53/150]\n",
            "0.007766570895910263\n",
            "Epoch [54/150]\n",
            "0.008068632334470749\n",
            "Epoch [55/150]\n",
            "0.008359611965715885\n",
            "Epoch [56/150]\n",
            "0.007982761599123478\n",
            "Epoch [57/150]\n",
            "0.008229068480432034\n",
            "Epoch [58/150]\n",
            "0.007921130396425724\n",
            "Epoch [59/150]\n",
            "0.007348794490098953\n",
            "Epoch [60/150]\n",
            "0.00702728470787406\n",
            "Epoch [61/150]\n",
            "0.008134235627949238\n",
            "Epoch [62/150]\n",
            "0.007025845814496279\n",
            "Epoch [63/150]\n",
            "0.007086996920406818\n",
            "Epoch [64/150]\n",
            "0.007158835884183645\n",
            "Epoch [65/150]\n",
            "0.00795372948050499\n",
            "Epoch [66/150]\n",
            "0.0071537368930876255\n",
            "Epoch [67/150]\n",
            "0.007463997229933739\n",
            "Epoch [68/150]\n",
            "0.008393332362174988\n",
            "Epoch [69/150]\n",
            "0.007161007262766361\n",
            "Epoch [70/150]\n",
            "0.008509357459843159\n",
            "Epoch [71/150]\n",
            "0.007414069026708603\n",
            "Epoch [72/150]\n",
            "0.008339397609233856\n",
            "Epoch [73/150]\n",
            "0.008186872117221355\n",
            "Epoch [74/150]\n",
            "0.007388052064925432\n",
            "Epoch [75/150]\n",
            "0.007515073753893375\n",
            "Epoch [76/150]\n",
            "0.0075536491349339485\n",
            "Epoch [77/150]\n",
            "0.00737351831048727\n",
            "Epoch [78/150]\n",
            "0.007695693988353014\n",
            "Epoch [79/150]\n",
            "0.007438983768224716\n",
            "Epoch [80/150]\n",
            "0.007193208672106266\n",
            "Epoch [81/150]\n",
            "0.006759552285075188\n",
            "Epoch [82/150]\n",
            "0.0064342743717134\n",
            "Epoch [83/150]\n",
            "0.007556383963674307\n",
            "Epoch [84/150]\n",
            "0.007055104710161686\n",
            "Epoch [85/150]\n",
            "0.006862075533717871\n",
            "Epoch [86/150]\n",
            "0.006412500515580177\n",
            "Epoch [87/150]\n",
            "0.007573900278657675\n",
            "Epoch [88/150]\n",
            "0.007180660031735897\n",
            "Epoch [89/150]\n",
            "0.006935862824320793\n",
            "Epoch [90/150]\n",
            "0.006679238751530647\n",
            "Epoch [91/150]\n",
            "0.007431271485984325\n",
            "Epoch [92/150]\n",
            "0.006680688820779324\n",
            "Epoch [93/150]\n",
            "0.006598292849957943\n",
            "Epoch [94/150]\n",
            "0.007018694654107094\n",
            "Epoch [95/150]\n",
            "0.006696209777146578\n",
            "Epoch [96/150]\n",
            "0.007406866177916527\n",
            "Epoch [97/150]\n",
            "0.0074605802074074745\n",
            "Epoch [98/150]\n",
            "0.006604546681046486\n",
            "Epoch [99/150]\n",
            "0.006987622939050198\n",
            "Epoch [100/150]\n",
            "0.007116323336958885\n",
            "Epoch [101/150]\n",
            "0.006817050743848085\n",
            "Epoch [102/150]\n",
            "0.006601131521165371\n",
            "Epoch [103/150]\n",
            "0.006409164518117905\n",
            "Epoch [104/150]\n",
            "0.006031735800206661\n",
            "Epoch [105/150]\n",
            "0.0057096295058727264\n",
            "Epoch [106/150]\n",
            "0.00656932033598423\n",
            "Epoch [107/150]\n",
            "0.005960171110928059\n",
            "Epoch [108/150]\n",
            "0.0063851214945316315\n",
            "Epoch [109/150]\n",
            "0.006256247870624065\n",
            "Epoch [110/150]\n",
            "0.006744705140590668\n",
            "Epoch [111/150]\n",
            "0.0058756545186042786\n",
            "Epoch [112/150]\n",
            "0.006754603702574968\n",
            "Epoch [113/150]\n",
            "0.005729397758841515\n",
            "Epoch [114/150]\n",
            "0.006866924464702606\n",
            "Epoch [115/150]\n",
            "0.005965053103864193\n",
            "Epoch [116/150]\n",
            "0.006726962514221668\n",
            "Epoch [117/150]\n",
            "0.005808359477669001\n",
            "Epoch [118/150]\n",
            "0.006069480907171965\n",
            "Epoch [119/150]\n",
            "0.006401969585567713\n",
            "Epoch [120/150]\n",
            "0.0059630610048770905\n",
            "Epoch [121/150]\n",
            "0.0061675491742789745\n",
            "Epoch [122/150]\n",
            "0.006315216887742281\n",
            "Epoch [123/150]\n",
            "0.006177032832056284\n",
            "Epoch [124/150]\n",
            "0.0058838678523898125\n",
            "Epoch [125/150]\n",
            "0.0060302987694740295\n",
            "Epoch [126/150]\n",
            "0.006411599926650524\n",
            "Epoch [127/150]\n",
            "0.007143914233893156\n",
            "Epoch [128/150]\n",
            "0.0061988020315766335\n",
            "Epoch [129/150]\n",
            "0.006809225771576166\n",
            "Epoch [130/150]\n",
            "0.006608559284359217\n",
            "Epoch [131/150]\n",
            "0.007014561910182238\n",
            "Epoch [132/150]\n",
            "0.006617164239287376\n",
            "Epoch [133/150]\n",
            "0.006825045216828585\n",
            "Epoch [134/150]\n",
            "0.005750088486820459\n",
            "Epoch [135/150]\n",
            "0.006132279057055712\n",
            "Epoch [136/150]\n",
            "0.0068725161254405975\n",
            "Epoch [137/150]\n",
            "0.00716294813901186\n",
            "Epoch [138/150]\n",
            "0.006932294461876154\n",
            "Epoch [139/150]\n",
            "0.006352008320391178\n",
            "Epoch [140/150]\n",
            "0.006040334701538086\n",
            "Epoch [141/150]\n",
            "0.007116108667105436\n",
            "Epoch [142/150]\n",
            "0.006200068164616823\n",
            "Epoch [143/150]\n",
            "0.006142077501863241\n",
            "Epoch [144/150]\n",
            "0.007479717489331961\n",
            "Epoch [145/150]\n",
            "0.006681802682578564\n",
            "Epoch [146/150]\n",
            "0.006086103618144989\n",
            "Epoch [147/150]\n",
            "0.006275694817304611\n",
            "Epoch [148/150]\n",
            "0.006733575835824013\n",
            "Epoch [149/150]\n",
            "0.006518273148685694\n",
            "Epoch [150/150]\n",
            "0.006225774064660072\n"
          ]
        }
      ],
      "source": [
        "train(model, train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEkM0M2wITgk"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/情感分类实验数据2023/CNN.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnR14tOIhje5",
        "outputId": "ba3f830a-c86d-4043-8c71-79efa45f588d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CNN(w2v)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/情感分类实验数据2023/CNN.pt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b5MHNvqhDq0",
        "outputId": "3b8ecad2-3f0d-4661-f649-97b87b484b97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [00:00<00:00, 3624.13it/s]\n"
          ]
        }
      ],
      "source": [
        "test_data = Mydataset('/content/drive/MyDrive/情感分类实验数据2023/public-data/test_data/test.json', mode='test', wv=w2v)\n",
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ8Op-LKIoMw",
        "outputId": "e5d67eaf-a10f-446c-b3e2-859b9e86aeef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2000/2000 [00:00<00:00, 4631.37it/s]\n"
          ]
        }
      ],
      "source": [
        "dev_data = Mydataset('/content/drive/MyDrive/情感分类实验数据2023/public-data/eval_data/eval_data.json', mode='train', wv=w2v)\n",
        "dev_loader = DataLoader(dev_data, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmbuhrbAh9SO"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as Fun\n",
        "\n",
        "def dev(model, dev_iter):\n",
        "  model.eval()\n",
        "  loss_total, acc = 0, 0\n",
        "  eval_all = np.array([], dtype=int)\n",
        "  with torch.no_grad():\n",
        "    for i, (text, label) in enumerate(tqdm(dev_iter)):\n",
        "      outputs = model(text)\n",
        "      loss = Fun.cross_entropy(outputs, label)\n",
        "      loss_total += loss\n",
        "      acc += sum([1 if mylabel == truelabel else 0 for mylabel, truelabel in zip(torch.max(outputs.cpu().data, 1)[1].numpy(), label.numpy())])\n",
        "      eval_all = np.append(eval_all, torch.max(outputs.cpu().data, 1)[1].numpy())\n",
        "  print(f'\\nacc:{acc/len(dev_data)}, total_loss:{loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w4xvDwSkJYT",
        "outputId": "eb084d58-3367-4f14-ba49-3a4ef5994167"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 125/125 [00:00<00:00, 314.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "acc:0.7345, total_loss:1.3434284925460815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dev(model, dev_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5eet5a1JTB6"
      },
      "outputs": [],
      "source": [
        "def test(model, test_iter):\n",
        "  model.eval()\n",
        "  predict_all, predict_result = np.array([], dtype=int), []\n",
        "  with torch.no_grad():\n",
        "    for trains in tqdm(test_iter):\n",
        "      outputs = model(trains)\n",
        "      predict_all = np.append(predict_all, torch.max(outputs.cpu().data, 1)[1].numpy())\n",
        "  for i, label in enumerate(predict_all):\n",
        "    predict_result.append([i + 1, label])\n",
        "  predict = pd.DataFrame(predict_result)\n",
        "  predict.to_csv('/content/drive/MyDrive/情感分类实验数据2023/predict.csv', index = False, header = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-JZiTbgJrsp",
        "outputId": "86a69d37-e8dc-4ff6-ea1e-361ca26882ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 188/188 [00:00<00:00, 318.28it/s]\n"
          ]
        }
      ],
      "source": [
        "test(model, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
