{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2TePrntrbwH",
        "outputId": "4198ab72-9119-4ad4-8147-9296c5e62bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gensim\n",
        "import jieba\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "UbIyWHfsrlig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAD = '<PAD>'\n",
        "UNK = '<UNK>'\n",
        "\n",
        "label_dic = {'positive': 1, 'negative': 2, 'neutral': 0}\n",
        "\n",
        "def read_json(file_path):\n",
        "    with open(file_path, 'r', encoding = 'utf-8') as f:\n",
        "      anslist = json.load(f)\n",
        "    return anslist\n",
        "\n",
        "def build_dataset(file_path, mode, wv, padding_size = 32):\n",
        "    assert mode in ['train', 'test']\n",
        "    res = read_json(file_path)\n",
        "    text, labels = [], []\n",
        "    for dic in tqdm(res):\n",
        "        corpus = dic['content']\n",
        "        if mode == 'train':\n",
        "            label = label_dic[dic['label']]\n",
        "        words = list(jieba.cut(corpus))\n",
        "        if len(words) < padding_size:\n",
        "            words += [PAD] * (padding_size - len(words))\n",
        "        else:\n",
        "            words = words[: padding_size]\n",
        "        unk_idx = wv.word2idx[UNK]\n",
        "        idxs = [wv.word2idx.get(word, unk_idx) for word in words]\n",
        "        if mode == 'train':\n",
        "            text.append(idxs)\n",
        "            labels.append(label)\n",
        "        else:\n",
        "            text.append(idxs)\n",
        "    if mode == 'train':\n",
        "        return text, labels\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "class Mydataset(Dataset):\n",
        "    def __init__(self, file_path, mode, wv):\n",
        "        if mode == 'train':\n",
        "            self.x, self.y = build_dataset(file_path, mode, wv)\n",
        "            assert len(self.x) == len(self.y)\n",
        "            self.y = torch.tensor(self.y)\n",
        "        else:\n",
        "            self.x = build_dataset(file_path, mode, wv)\n",
        "        self.mode = mode\n",
        "        self.x = torch.tensor(self.x)\n",
        "        self.len = len(self.x)\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    def __getitem__(self, index):\n",
        "        if self.mode == 'train':\n",
        "            return self.x[index], self.y[index]\n",
        "        else:\n",
        "            return self.x[index]"
      ],
      "metadata": {
        "id": "Jo8uiwYSrnBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class word2vec():\n",
        "  def __init__(self, pretrained_w2v_path = '/content/drive/MyDrive/情感分类实验数据2023/sgns.weibo.bigram-char'):\n",
        "    w2vmodel = gensim.models.KeyedVectors.load_word2vec_format(pretrained_w2v_path, binary = False, encoding = 'utf-8')\n",
        "    self.vocab_size = len(w2vmodel.index_to_key)\n",
        "    self.word2idx = w2vmodel.key_to_index\n",
        "    self.word2idx.update({'<UNK>': self.vocab_size, '<PAD>': self.vocab_size + 1})\n",
        "    self.vocab_size += 2\n",
        "    self.vector_size = w2vmodel.vector_size\n",
        "    self.vocab = w2vmodel.index_to_key\n",
        "    self.vocab.append('<UNK>')\n",
        "    self.vocab.append('<PAD>')\n",
        "    self.vectors = w2vmodel.vectors\n",
        "    self.vectors = torch.tensor(np.append(np.append(\n",
        "        self.vectors, self.vectors.mean(axis=0).reshape(1,-1), axis=0),\n",
        "        self.vectors.mean(axis=0).reshape(1,-1), axis=0))"
      ],
      "metadata": {
        "id": "HFT2l2v_rpBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, w2vmodel, drop_rate = 0.3):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.embedding = nn.Embedding.from_pretrained(w2vmodel.vectors, freeze=True)\n",
        "    embedding_dim = w2vmodel.vector_size\n",
        "    self.LSTM = nn.LSTM(embedding_dim, 32, num_layers=3, bidirectional=True, batch_first=True, dropout=drop_rate)\n",
        "    self.Fc = nn.Linear(64, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.embedding(x)\n",
        "    output, _ = self.LSTM(output)\n",
        "    output = self.Fc(output[:, -1, :])\n",
        "    return output"
      ],
      "metadata": {
        "id": "QT2LYzEErrYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v = word2vec()"
      ],
      "metadata": {
        "id": "-Bo19EST45E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(w2v)"
      ],
      "metadata": {
        "id": "7j1h3osz47pK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Mydataset('/content/drive/MyDrive/情感分类实验数据2023/public-data/train_data/train_data.json', mode='train', wv=w2v)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v87qzUdh4pSX",
        "outputId": "efa41a75-a5fa-48a1-c9a5-34b7b329f403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8606 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.259 seconds.\n",
            "DEBUG:jieba:Loading model cost 1.259 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n",
            "100%|██████████| 8606/8606 [00:03<00:00, 2234.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as Fun\n",
        "\n",
        "def train(model, train_iter):\n",
        "    # 启用dropout\n",
        "    model.train()\n",
        "    # 设置adam优化器\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    for epoch in range(150):\n",
        "      print(\"Epoch [{}/{}]\".format(epoch+1, 150))\n",
        "      for i, (trains, labels) in enumerate(train_iter):\n",
        "        outputs = model(trains)\n",
        "        model.zero_grad()\n",
        "        loss = Fun.cross_entropy(outputs, labels)\n",
        "        if i == 0:\n",
        "          print(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "YP_27Tlf5ABo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, train_loader)"
      ],
      "metadata": {
        "id": "kGR0Oomy42BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/情感分类实验数据2023/LSTM.pt')"
      ],
      "metadata": {
        "id": "a868A-RK8fT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(w2v)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/情感分类实验数据2023/LSTM.pt'))"
      ],
      "metadata": {
        "id": "f7Eqb7_k8itp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_data = Mydataset('/content/drive/MyDrive/情感分类实验数据2023/public-data/eval_data/eval_data.json', mode='train', wv=w2v)\n",
        "dev_loader = DataLoader(dev_data, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPr_PEa-8ltT",
        "outputId": "f7bf59d0-fbc8-488b-8513-c5903b6c6d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [00:00<00:00, 4527.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = Mydataset('/content/drive/MyDrive/情感分类实验数据2023/public-data/test_data/test.json', mode='test', wv=w2v)\n",
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp92r1p-8nK1",
        "outputId": "61725f71-72ea-4717-d346-1e3d88304953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:00<00:00, 4289.23it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as Fun\n",
        "\n",
        "def dev(model, dev_iter):\n",
        "  model.eval()\n",
        "  loss_total, acc = 0, 0\n",
        "  eval_all = np.array([], dtype=int)\n",
        "  with torch.no_grad():\n",
        "    for i, (text, label) in enumerate(tqdm(dev_iter)):\n",
        "      outputs = model(text)\n",
        "      loss = Fun.cross_entropy(outputs, label)\n",
        "      loss_total += loss\n",
        "      acc += sum([1 if mylabel == truelabel else 0 for mylabel, truelabel in zip(torch.max(outputs.cpu().data, 1)[1].numpy(), label.numpy())])\n",
        "      eval_all = np.append(eval_all, torch.max(outputs.cpu().data, 1)[1].numpy())\n",
        "  print(f'\\nacc:{acc/len(dev_data)}, total_loss:{loss}')"
      ],
      "metadata": {
        "id": "Yw4vQMgl8ode"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev(model, dev_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-1UVddg8qku",
        "outputId": "3ef56147-390f-484b-eafb-dae97980424f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:00<00:00, 264.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "acc:0.7355, total_loss:1.831783413887024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_iter, save_path):\n",
        "  model.eval()\n",
        "  predict_all, predict_result = np.array([], dtype=int), []\n",
        "  with torch.no_grad():\n",
        "    for trains in tqdm(test_iter):\n",
        "      outputs = model(trains)\n",
        "      predict_all = np.append(predict_all, torch.max(outputs.cpu().data, 1)[1].numpy())\n",
        "  for i, label in enumerate(predict_all):\n",
        "    predict_result.append([i + 1, label])\n",
        "  predict = pd.DataFrame(predict_result)\n",
        "  predict.to_csv(save_path, index = False, header = False)"
      ],
      "metadata": {
        "id": "jdjyAmvD8rm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, test_loader, '/content/drive/MyDrive/情感分类实验数据2023/predict_LSTM.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrzVDaco8skZ",
        "outputId": "2ca0d369-3c85-45de-9dff-f5c7e1742238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 188/188 [00:00<00:00, 262.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataset_no_padding(file_path, mode, wv):\n",
        "    assert mode in ['train', 'test']\n",
        "    res = read_json(file_path)\n",
        "    text, labels = [], []\n",
        "    for dic in tqdm(res):\n",
        "        corpus = dic['content']\n",
        "        if mode == 'train':\n",
        "            label = label_dic[dic['label']]\n",
        "        words = list(jieba.cut(corpus))\n",
        "        unk_idx = wv.word2idx[UNK]\n",
        "        idxs = torch.tensor([wv.word2idx.get(word, unk_idx) for word in words])\n",
        "        if mode == 'train':\n",
        "            text.append(idxs)\n",
        "            labels.append(label)\n",
        "        else:\n",
        "            text.append(idxs)\n",
        "    if mode == 'train':\n",
        "        return text, labels\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "class Mydataset_no_padding(Dataset):\n",
        "    def __init__(self, file_path, mode, wv):\n",
        "        if mode == 'train':\n",
        "            self.x, self.y = build_dataset_no_padding(file_path, mode, wv)\n",
        "            assert len(self.x) == len(self.y)\n",
        "            self.y = torch.tensor(self.y)\n",
        "        else:\n",
        "            self.x = build_dataset(file_path, mode, wv)\n",
        "        self.mode = mode\n",
        "        self.len = len(self.x)\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    def __getitem__(self, index):\n",
        "        if self.mode == 'train':\n",
        "            return self.x[index], self.y[index]\n",
        "        else:\n",
        "            return self.x[index]"
      ],
      "metadata": {
        "id": "-64jpczI_RFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(train_data):\n",
        "  txt, label = zip(*train_data)\n",
        "  txt = nn.utils.rnn.pad_sequence(txt, batch_first=True, padding_value=0)\n",
        "  return txt, torch.tensor(label)"
      ],
      "metadata": {
        "id": "S9KUnUtT_4kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_padding_train_data = Mydataset_no_padding('/content/drive/MyDrive/情感分类实验数据2023/public-data/train_data/train_data.json', 'train', w2v)\n",
        "no_padding_train_loader = DataLoader(no_padding_train_data, batch_size=16, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93wFdAUl_b5O",
        "outputId": "83f99c97-b043-4984-997e-788db424acc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8606/8606 [00:02<00:00, 3037.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_padding_model = LSTM(w2v)"
      ],
      "metadata": {
        "id": "SxYSh31oBGje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(no_padding_model, no_padding_train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHFtfD3hBR9E",
        "outputId": "8ec03eb9-da6a-4f13-c8ac-cef5408168b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/150]\n",
            "1.1696312427520752\n",
            "Epoch [2/150]\n",
            "0.7966829538345337\n",
            "Epoch [3/150]\n",
            "0.5051431059837341\n",
            "Epoch [4/150]\n",
            "0.5211045742034912\n",
            "Epoch [5/150]\n",
            "0.6621553301811218\n",
            "Epoch [6/150]\n",
            "0.4631933569908142\n",
            "Epoch [7/150]\n",
            "0.3347940146923065\n",
            "Epoch [8/150]\n",
            "0.27229049801826477\n",
            "Epoch [9/150]\n",
            "0.33727675676345825\n",
            "Epoch [10/150]\n",
            "0.1788896918296814\n",
            "Epoch [11/150]\n",
            "0.1550033837556839\n",
            "Epoch [12/150]\n",
            "0.13392925262451172\n",
            "Epoch [13/150]\n",
            "0.11539328098297119\n",
            "Epoch [14/150]\n",
            "0.07143248617649078\n",
            "Epoch [15/150]\n",
            "0.07877279818058014\n",
            "Epoch [16/150]\n",
            "0.09784678369760513\n",
            "Epoch [17/150]\n",
            "0.04177502170205116\n",
            "Epoch [18/150]\n",
            "0.02188311330974102\n",
            "Epoch [19/150]\n",
            "0.023423045873641968\n",
            "Epoch [20/150]\n",
            "0.01709747686982155\n",
            "Epoch [21/150]\n",
            "0.018516259267926216\n",
            "Epoch [22/150]\n",
            "0.057692863047122955\n",
            "Epoch [23/150]\n",
            "0.04360463097691536\n",
            "Epoch [24/150]\n",
            "0.1422058492898941\n",
            "Epoch [25/150]\n",
            "0.011003856547176838\n",
            "Epoch [26/150]\n",
            "0.01336454413831234\n",
            "Epoch [27/150]\n",
            "0.01953195407986641\n",
            "Epoch [28/150]\n",
            "0.017946526408195496\n",
            "Epoch [29/150]\n",
            "0.009230921976268291\n",
            "Epoch [30/150]\n",
            "0.013475371524691582\n",
            "Epoch [31/150]\n",
            "0.009071024134755135\n",
            "Epoch [32/150]\n",
            "0.011116335168480873\n",
            "Epoch [33/150]\n",
            "0.01340500172227621\n",
            "Epoch [34/150]\n",
            "0.015785733237862587\n",
            "Epoch [35/150]\n",
            "0.018590733408927917\n",
            "Epoch [36/150]\n",
            "0.02581554651260376\n",
            "Epoch [37/150]\n",
            "0.013147370889782906\n",
            "Epoch [38/150]\n",
            "0.045444101095199585\n",
            "Epoch [39/150]\n",
            "0.007432358339428902\n",
            "Epoch [40/150]\n",
            "0.011354529298841953\n",
            "Epoch [41/150]\n",
            "0.009370008483529091\n",
            "Epoch [42/150]\n",
            "0.009290027432143688\n",
            "Epoch [43/150]\n",
            "0.011457361280918121\n",
            "Epoch [44/150]\n",
            "0.0075128041207790375\n",
            "Epoch [45/150]\n",
            "0.010064609348773956\n",
            "Epoch [46/150]\n",
            "0.01357068121433258\n",
            "Epoch [47/150]\n",
            "0.1857101023197174\n",
            "Epoch [48/150]\n",
            "0.0886891707777977\n",
            "Epoch [49/150]\n",
            "0.009360004216432571\n",
            "Epoch [50/150]\n",
            "0.011342285200953484\n",
            "Epoch [51/150]\n",
            "0.006797955371439457\n",
            "Epoch [52/150]\n",
            "0.010844305157661438\n",
            "Epoch [53/150]\n",
            "0.008069931529462337\n",
            "Epoch [54/150]\n",
            "0.010071951895952225\n",
            "Epoch [55/150]\n",
            "0.006048270966857672\n",
            "Epoch [56/150]\n",
            "0.009136071428656578\n",
            "Epoch [57/150]\n",
            "0.006199589464813471\n",
            "Epoch [58/150]\n",
            "0.02462642267346382\n",
            "Epoch [59/150]\n",
            "0.008593660779297352\n",
            "Epoch [60/150]\n",
            "0.03623620420694351\n",
            "Epoch [61/150]\n",
            "0.007814600132405758\n",
            "Epoch [62/150]\n",
            "0.006518935784697533\n",
            "Epoch [63/150]\n",
            "0.01416165754199028\n",
            "Epoch [64/150]\n",
            "0.007098198868334293\n",
            "Epoch [65/150]\n",
            "0.006430536508560181\n",
            "Epoch [66/150]\n",
            "0.008349120616912842\n",
            "Epoch [67/150]\n",
            "0.005941071547567844\n",
            "Epoch [68/150]\n",
            "0.008356270380318165\n",
            "Epoch [69/150]\n",
            "0.007277154829353094\n",
            "Epoch [70/150]\n",
            "0.007766260765492916\n",
            "Epoch [71/150]\n",
            "0.00963764637708664\n",
            "Epoch [72/150]\n",
            "0.06012006849050522\n",
            "Epoch [73/150]\n",
            "0.007270123343914747\n",
            "Epoch [74/150]\n",
            "0.008692418225109577\n",
            "Epoch [75/150]\n",
            "0.009684945456683636\n",
            "Epoch [76/150]\n",
            "0.005710747558623552\n",
            "Epoch [77/150]\n",
            "0.005303970538079739\n",
            "Epoch [78/150]\n",
            "0.008185097016394138\n",
            "Epoch [79/150]\n",
            "0.008231114596128464\n",
            "Epoch [80/150]\n",
            "0.006734649650752544\n",
            "Epoch [81/150]\n",
            "0.0066499123349785805\n",
            "Epoch [82/150]\n",
            "0.005915207788348198\n",
            "Epoch [83/150]\n",
            "0.051356665790081024\n",
            "Epoch [84/150]\n",
            "0.008553856983780861\n",
            "Epoch [85/150]\n",
            "0.008349744603037834\n",
            "Epoch [86/150]\n",
            "0.005189456045627594\n",
            "Epoch [87/150]\n",
            "0.00661119632422924\n",
            "Epoch [88/150]\n",
            "0.006516503170132637\n",
            "Epoch [89/150]\n",
            "0.007976620458066463\n",
            "Epoch [90/150]\n",
            "0.005747773218899965\n",
            "Epoch [91/150]\n",
            "0.005197770427912474\n",
            "Epoch [92/150]\n",
            "0.006387538276612759\n",
            "Epoch [93/150]\n",
            "0.006869233679026365\n",
            "Epoch [94/150]\n",
            "0.005588711705058813\n",
            "Epoch [95/150]\n",
            "0.006446249317377806\n",
            "Epoch [96/150]\n",
            "0.004394731484353542\n",
            "Epoch [97/150]\n",
            "0.009207064285874367\n",
            "Epoch [98/150]\n",
            "0.0417451374232769\n",
            "Epoch [99/150]\n",
            "0.00484235305339098\n",
            "Epoch [100/150]\n",
            "0.0070133451372385025\n",
            "Epoch [101/150]\n",
            "0.005701187066733837\n",
            "Epoch [102/150]\n",
            "0.005769096780568361\n",
            "Epoch [103/150]\n",
            "0.03495175391435623\n",
            "Epoch [104/150]\n",
            "0.004719748627394438\n",
            "Epoch [105/150]\n",
            "0.007587791886180639\n",
            "Epoch [106/150]\n",
            "0.004742946941405535\n",
            "Epoch [107/150]\n",
            "0.004275599028915167\n",
            "Epoch [108/150]\n",
            "0.004718984477221966\n",
            "Epoch [109/150]\n",
            "0.005182615946978331\n",
            "Epoch [110/150]\n",
            "0.004312770441174507\n",
            "Epoch [111/150]\n",
            "0.003852201160043478\n",
            "Epoch [112/150]\n",
            "0.005144831724464893\n",
            "Epoch [113/150]\n",
            "0.0058023566380143166\n",
            "Epoch [114/150]\n",
            "0.0034682643599808216\n",
            "Epoch [115/150]\n",
            "0.02157278172671795\n",
            "Epoch [116/150]\n",
            "0.004659094847738743\n",
            "Epoch [117/150]\n",
            "0.006924080662429333\n",
            "Epoch [118/150]\n",
            "0.012862052768468857\n",
            "Epoch [119/150]\n",
            "0.014709335751831532\n",
            "Epoch [120/150]\n",
            "0.008919261395931244\n",
            "Epoch [121/150]\n",
            "0.004778242204338312\n",
            "Epoch [122/150]\n",
            "0.006530441343784332\n",
            "Epoch [123/150]\n",
            "0.004793566185981035\n",
            "Epoch [124/150]\n",
            "0.003542768070474267\n",
            "Epoch [125/150]\n",
            "0.004177164286375046\n",
            "Epoch [126/150]\n",
            "0.00542998593300581\n",
            "Epoch [127/150]\n",
            "0.00711170956492424\n",
            "Epoch [128/150]\n",
            "0.004385459236800671\n",
            "Epoch [129/150]\n",
            "0.003994420170783997\n",
            "Epoch [130/150]\n",
            "0.0032401923090219498\n",
            "Epoch [131/150]\n",
            "0.0231110118329525\n",
            "Epoch [132/150]\n",
            "0.006406925152987242\n",
            "Epoch [133/150]\n",
            "0.004368051420897245\n",
            "Epoch [134/150]\n",
            "0.002843596041202545\n",
            "Epoch [135/150]\n",
            "0.003476726356893778\n",
            "Epoch [136/150]\n",
            "0.0026571282651275396\n",
            "Epoch [137/150]\n",
            "0.002720840275287628\n",
            "Epoch [138/150]\n",
            "0.0027679589111357927\n",
            "Epoch [139/150]\n",
            "0.002884011249989271\n",
            "Epoch [140/150]\n",
            "0.0031751501373946667\n",
            "Epoch [141/150]\n",
            "0.0029954782221466303\n",
            "Epoch [142/150]\n",
            "0.002508430276066065\n",
            "Epoch [143/150]\n",
            "0.0022517682518810034\n",
            "Epoch [144/150]\n",
            "0.0031860722228884697\n",
            "Epoch [145/150]\n",
            "0.0020451173186302185\n",
            "Epoch [146/150]\n",
            "0.0022307925391942263\n",
            "Epoch [147/150]\n",
            "0.0025831053499132395\n",
            "Epoch [148/150]\n",
            "0.09245201200246811\n",
            "Epoch [149/150]\n",
            "0.0032730381935834885\n",
            "Epoch [150/150]\n",
            "0.01130735408514738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(no_padding_model.state_dict(), '/content/drive/MyDrive/情感分类实验数据2023/NO_PADDING_LSTM.pt')"
      ],
      "metadata": {
        "id": "Gx738BcjSafd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_padding_dev_data = Mydataset('/content/drive/MyDrive/情感分类实验数据2023/public-data/eval_data/eval_data.json', 'train', w2v)\n",
        "no_padding_dev_loader = DataLoader(no_padding_dev_data, batch_size=16, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovLvUYYNHg_d",
        "outputId": "8c98e7fe-4436-459d-efcb-d0f8c3895c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [00:00<00:00, 5001.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev(no_padding_model, no_padding_dev_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGYMK5xRHnDP",
        "outputId": "cc70853e-56c0-47f6-94ee-3342b9920884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 125/125 [00:00<00:00, 231.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "acc:0.703, total_loss:1.45534086227417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn2(train_data):\n",
        "  txt = nn.utils.rnn.pad_sequence(train_data, batch_first=True, padding_value=0)\n",
        "  return txt"
      ],
      "metadata": {
        "id": "M1Dt_3mmelII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_padding_test_data = Mydataset('/content/drive/MyDrive/情感分类实验数据2023/public-data/test_data/test.json', 'test', w2v)\n",
        "no_padding_test_loader = DataLoader(no_padding_test_data, batch_size=16, shuffle=False, collate_fn=collate_fn2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFENp_RRIB1a",
        "outputId": "8fa4da18-7651-4b21-df90-4b6046031687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3000/3000 [00:00<00:00, 5053.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(no_padding_model, no_padding_test_loader, '/content/drive/MyDrive/情感分类实验数据2023/predict_np_LSTM.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et5Ymgq0HzSg",
        "outputId": "efbdf35b-184f-489f-8593-9a3eaa81b2cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 188/188 [00:01<00:00, 155.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#18:35 start"
      ],
      "metadata": {
        "id": "aK7ZX75kJDzA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}